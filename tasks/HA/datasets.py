'''
Author: Dylan Li dylan.h.li@outlook.com
Date: 2024-03-17 21:42:00
LastEditors: Dylan Li dylan.h.li@outlook.com
LastEditTime: 2024-03-30 22:46:08
FilePath: /HA3D_simulator/tasks/HA/datasets.py
Description: 

Copyright (c) 2024 by Heng Li, All Rights Reserved. 
'''
import torch
from multiprocessing import Process
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
from dataclasses import dataclass

from utils import write_vocab,build_vocab
from env import HABatch
from agent import RandomAgent, TeacherAgent
import pickle

from transformers import BartTokenizer, BartModel

import sys
module_path = '/home/dylan/projects/motion_hcl/Matterport3DSimulator/build'
if module_path not in sys.path:
    sys.path.append(module_path)
    
@dataclass
class Config:
    TRAIN_VOCAB: str = 'tasks/HA/data/train_vocab.txt'
    TRAINVAL_VOCAB: str = 'tasks/HA/data/trainval_vocab.txt'
    RESULT_DIR: str = 'tasks/HA/results/'
    SNAPSHOT_DIR: str = 'tasks/HA/snapshots/'
    PLOT_DIR: str = 'tasks/HA/plots/'
    TRAJS_DIR: str = 'tasks/HA/trajs'
    IMAGENET_FEATURES: str = 'img_features/ResNet-152-imagenet_80_16_mean.tsv'
    features: str = IMAGENET_FEATURES
    batch_size: int = 100
    n_iters: int = 100 # the total trajectory number of the training process will be n_iters * batch_size
    dataset_name = 'right_left_random_mix_teacher'


def setup(dataset_cfg):
    """
    Prepares the training environment by setting a fixed random seed for reproducibility and ensuring necessary vocabulary files exist.
    
    This function performs the following actions:
    1. Sets a fixed random seed for both PyTorch and its CUDA backend to ensure reproducible results.
    2. Checks for the existence of the training vocabulary file. If it does not exist, it builds the vocabulary from the 'train' data split and writes it to the specified file.
    3. Checks for the existence of the training and validation vocabulary file. If it does not exist, it builds the vocabulary from the 'train', 'val_seen', and 'val_unseen' data splits and writes it to the specified file.
    
    Parameters:
    None
    
    Returns:
    None
    """
    torch.manual_seed(1)
    torch.cuda.manual_seed(1)
    # Check for vocabs
    if not os.path.exists(dataset_cfg.TRAIN_VOCAB):
        write_vocab(build_vocab(splits=['train']), dataset_cfg.TRAIN_VOCAB)
    if not os.path.exists(dataset_cfg.TRAINVAL_VOCAB):
        write_vocab(build_vocab(splits=['train','val_seen','val_unseen']), dataset_cfg.TRAINVAL_VOCAB)


def train_random(train_env, n_iters, log_every=100, val_envs={}):
    """
    Trains a random agent on a given environment for a specified number of iterations.
    
    This function simulates training by having a random agent perform actions within the environment. It is primarily used for baseline comparisons and does not involve any learning or optimization. The function collects trajectories generated by the agent's interactions with the environment.
    
    Parameters:
    - train_env: The training environment where the agent will perform actions.
    - n_iters: The number of iterations to simulate. Each iteration corresponds to a complete trajectory of agent-environment interaction.
    - log_every: The frequency (in iterations) at which to log progress. Default is 100.
    - val_envs: A dictionary of validation environments for evaluating the agent. Default is an empty dictionary. This parameter is not used in the function but included for interface consistency.
    
    Returns:
    - trajs: A list of trajectories. Each trajectory is a list of dictionaries, where each dictionary represents the state of the environment and the agent's action at each step of the interaction.
    """
    
    agent = RandomAgent(train_env, "")
    
    print('Random Agent Begins')
    trajs = []

    for _ in tqdm(range(0, n_iters)):
        
        # traj is a list of dictionaries, each of which is a episode, we have a batch of episodes
        traj = agent.rollout()
        trajs.extend(traj)
    
    return trajs 

def train_teacher(train_env, n_iters, log_every=100, val_envs={}):
    """
    Trains an agent using the teacher forcing method on a given training environment for a specified number of iterations.
    
    This function simulates training by having an agent (initialized as a RandomAgent for simplicity, but typically would be a learning agent) perform actions within the environment based on the teacher forcing strategy. The primary purpose is to generate trajectories that can be used for further analysis or training. The function collects these trajectories by executing the agent's rollout method, which simulates an entire episode of interaction with the environment.
    
    Parameters:
    - train_env: The training environment where the agent will perform actions. This environment should be capable of resetting and providing observations and rewards based on the agent's actions.
    - n_iters: The number of iterations to simulate. Each iteration corresponds to a complete trajectory of agent-environment interaction.
    - log_every: The frequency (in iterations) at which to log progress. Default is 100. This parameter is currently not used but included for future enhancements and consistency with other training functions.
    - val_envs: A dictionary of validation environments for evaluating the agent. Default is an empty dictionary. This parameter is not used in this function but included for interface consistency with other training functions.
    
    Returns:
    - trajs: A list of trajectories. Each trajectory is a list of dictionaries, where each dictionary represents the state of the environment and the agent's action at each step of the interaction. This data structure is useful for analyzing the agent's behavior and for training on the generated data.
    """
    
    agent = TeacherAgent(train_env, "")
    
    print('Teacher Agent Begins')
    trajs = []

    for _ in tqdm(range(0, n_iters)):
        
        # traj is a list of dictionaries, each of which is a episode, we have a batch of episodes
        traj = agent.rollout()
        trajs.extend(traj)
    
    return trajs

def train_run(iter, dataset_cfg, agent='random', gpu_id=0):
    """
    Trains an agent on the training set and saves the generated trajectories.

    This function sets up the training environment, initializes the tokenizer and embedding model, and iterates through the specified number of training iterations. For each iteration, it creates a new training environment, trains the agent (either a random or a teacher agent), and saves the generated trajectories to disk.

    Parameters:
    - iter (int): The number of training iterations to perform.
    - agent (str): The type of agent to train. Can be 'random' or 'teacher'. Default is 'random'.
    - gpu_id (int): The ID of the GPU to use for training. Default is 0.

    Returns:
    None
    """
    trajs_dir = os.path.join(dataset_cfg.TRAJS_DIR, agent)
    if not os.path.exists(trajs_dir):
        os.makedirs(trajs_dir)
    setup(dataset_cfg)
    device = f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu'
    
    tok = BartTokenizer.from_pretrained('facebook/bart-base')
    embedding_model = BartModel.from_pretrained('facebook/bart-base')
    
    for i in range(iter):
        train_env = HABatch(dataset_cfg.features, batch_size=dataset_cfg.batch_size, splits=['train'], tokenizer=tok, text_embedding_model=embedding_model, device=device)
        if agent == 'random':
            trajs = train_random(train_env, dataset_cfg.n_iters)
        elif agent == 'teacher':
            trajs = train_teacher(train_env, dataset_cfg.n_iters)
        with open(os.path.join(trajs_dir, f'train_trajs_{i}_{agent}_{dataset_cfg.dataset_name}.pkl'), 'wb') as f:
            pickle.dump(trajs, f)

def run_agent(dataset_cfg, agent, gpu_id, run):
    """
    Initiates the training process for a specified agent on a specified GPU.

    This function is a wrapper that calls the `train_run` function with a predefined number of iterations (10) and the specified agent and GPU ID. It is designed to be used as a target for multiprocessing, allowing for parallel training of different agents on different GPUs.

    Parameters:
    - agent (str): The type of agent to train. Can be 'random' or 'teacher'.
    - gpu_id (int): The ID of the GPU to use for training.

    Returns:
    None
    """
    train_run(run, dataset_cfg, agent=agent, gpu_id=gpu_id)

if __name__ == '__main__':
    # Main entry point for the script. Initializes and starts the training process for the specified agents in parallel.
    dataset_cfg = Config()
    agents = ['random', 'teacher']
    runs = [5, 1]
    processes = []
    for i, (agent, run) in enumerate(zip(agents, runs)):
        p = Process(target=run_agent, args=(dataset_cfg, agent, i+1, run))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()

